# Latent Control System Configuration
#
# This is the default production configuration.
# For platform-optimized configs, see:
#   - configs/windows.yaml  (Windows with/without GPU)
#   - configs/macos.yaml    (macOS with MPS or CPU)
#   - configs/linux.yaml    (Linux with CUDA)
#
# Configuration Guide:
# - model_path: Local path or HuggingFace model ID (e.g., "Qwen/Qwen2-7B-Instruct")
# - load_in_4bit: Enable 4-bit quantization (saves VRAM, requires bitsandbytes)
# - device: "cuda" (GPU), "mps" (Apple Silicon), or "cpu"
# - layer_fraction: Which layer to use for extraction (0.6 = 60% through model)
# - num_pairs: More pairs = better quality but slower training

model:
  model_path: "C:/models/Qwen3-4B-Instruct-2507-st"  # Replace with your local model path or HuggingFace model ID
  load_in_4bit: false               # Disabled by default for compatibility
  device: "cuda"                    # Auto-detects and falls back to CPU if unavailable
  layer_fraction: 0.6               # Layer for vector extraction (0.0-1.0)
  cache_dir: "vectors"              # Directory for cached trained vectors
  alpha_max_norm: 2.0               # Maximum alpha value normalization
  max_new_tokens: 256               # Maximum tokens to generate per request
  temperature: 0.7                  # Sampling temperature (higher = more random)
  top_p: 0.9                        # Nucleus sampling (0.9 = top 90% probability mass)
  random_seed: 42                   # Random seed for reproducibility

auto_train: true

datasets:
  safety:
    concept_a_path: "prompts/harmful.txt"
    concept_b_path: "prompts/harmless.txt"
    description: "Safety control (harmful vs harmless steering)"
    default_alpha: 2.0

  format:
    concept_a_path: "prompts/demo_style_narrative.txt"
    concept_b_path: "prompts/demo_style_bulleted.txt"
    description: "Output format control"
    default_alpha: 0.0

  emoji:
    concept_a_path: "prompts/demo_style_emoji.txt"
    concept_b_path: "prompts/demo_style_no_emoji.txt"
    description: "Emoji control"
    default_alpha: 0.0
